<html xmlns:MSHelp="http://msdn.microsoft.com/mshelp" xmlns:mshelp="http://msdn.microsoft.com/mshelp">
  <head>
    <link rel="SHORTCUT ICON" href="./../icons/favicon.ico" />
    <style type="text/css">.OH_CodeSnippetContainerTabLeftActive, .OH_CodeSnippetContainerTabLeft,.OH_CodeSnippetContainerTabLeftDisabled { backgroundImageName: tabLeftBG.gif; }.OH_CodeSnippetContainerTabRightActive, .OH_CodeSnippetContainerTabRight,.OH_CodeSnippetContainerTabRightDisabled { backgroundImageName: tabRightBG.gif; }.OH_footer { backgroundImageName: footer_slice.gif; background-position: top; background-repeat: repeat-x; }</style>
    <link rel="stylesheet" type="text/css" href="./../styles/branding.css" />
    <link rel="stylesheet" type="text/css" href="./../styles/branding-en-US.css" />
    <style type="text/css">
			body
			{
			border-left:5px solid #e6e6e6;
			overflow-x:scroll;
			overflow-y:scroll;
			}
		</style>
    <script src="./../scripts/branding.js" type="text/javascript">
      <!---->
    </script>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
    <title>PrincipalComponentAnalysis Class</title>
    <meta name="Language" content="en-us" />
    <meta name="System.Keywords" content="PrincipalComponentAnalysis class" />
    <meta name="System.Keywords" content="Accord.Statistics.Analysis.PrincipalComponentAnalysis class" />
    <meta name="System.Keywords" content="PrincipalComponentAnalysis class, about PrincipalComponentAnalysis class" />
    <meta name="Microsoft.Help.F1" content="Accord.Statistics.Analysis.PrincipalComponentAnalysis" />
    <meta name="Microsoft.Help.Id" content="T:Accord.Statistics.Analysis.PrincipalComponentAnalysis" />
    <meta name="Description" content="Principal component analysis (PCA) is a technique used to reduce multidimensional data sets to lower dimensions for analysis." />
    <meta name="Microsoft.Help.ContentType" content="Reference" />
    <meta name="BrandingAware" content="'true'" />
    <meta name="container" content="Accord.Statistics.Analysis" />
    <meta name="file" content="T_Accord_Statistics_Analysis_PrincipalComponentAnalysis" />
    <meta name="guid" content="T_Accord_Statistics_Analysis_PrincipalComponentAnalysis" />
    
    <link type="text/css" rel="stylesheet" href="ms-help://Hx/HxRuntime/HxLink.css" />
    <link type="text/css" rel="stylesheet" href="./../styles/highlight.css" />
    <script type="text/javascript" src="../scripts/highlight.js">
      <!---->
    </script>
    <meta name="SelfBranded" content="true" />
  </head>
  <body onload="onLoad()" class="primary-mtps-offline-document">
    <div class="OH_outerDiv">
      <div class="OH_outerContent">
        <table class="TitleTable">
          <tr>
            <td class="OH_tdLogoColumn">
              <img alt="Accord.NET (logo)" src="./../icons/logo.png" />
            </td>
            <td class="OH_tdTitleColumn">PrincipalComponentAnalysis Class</td>
            <td class="OH_tdRunningTitleColumn">Accord.NET Framework</td>
          </tr>
        </table>
        <div id="mainSection">
          <div id="mainBody">
            <span class="introStyle">
              <img src="./../icons/online_icon.gif" class="OH_offlineIcon" alt="Online" title="Online" />
              <a href="http://accord-net.github.io/docs/Index.html" target="_top">Show table of contents (goes to the online documentation index).</a>
              <br />
            </span>
            <div class="summary">
               Principal component analysis (PCA) is a technique used to reduce
               multidimensional data sets to lower dimensions for analysis.
             </div>
            <div class="OH_CollapsibleAreaRegion">
              <div class="OH_regiontitle">Inheritance Hierarchy</div>
              <div class="OH_CollapsibleArea_HrDiv">
                <hr class="OH_CollapsibleArea_Hr" />
              </div>
            </div>
            <div class="OH_clear"></div>
            <img src="./../icons/online_icon.gif" class="OH_offlineIcon" alt="Online" title="Online" />
            <a href="http://msdn2.microsoft.com/en-us/library/e5kfa45b" target="_blank">System<span id="ID0EBHOAAAAA"> </span><script type="text/javascript">
					addToLanSpecTextIdSet("ID0EBHOAAAAA?vb=.|cpp=::|cs=.|fs=.|nu=.");
				</script>Object</a>
            <br />  <span class="selflink">Accord.Statistics.Analysis<span id="ID0EBEOAAAAA"> </span><script type="text/javascript">
					addToLanSpecTextIdSet("ID0EBEOAAAAA?vb=.|cpp=::|cs=.|fs=.|nu=.");
				</script>PrincipalComponentAnalysis</span><br />    <a href="T_Accord_Statistics_Analysis_KernelPrincipalComponentAnalysis.htm" target="">Accord.Statistics.Analysis<span id="ID0EBBOAAAAA"> </span><script type="text/javascript">
					addToLanSpecTextIdSet("ID0EBBOAAAAA?vb=.|cpp=::|cs=.|fs=.|nu=.");
				</script>KernelPrincipalComponentAnalysis</a><br /><p></p><b>Namespace:</b> <a href="N_Accord_Statistics_Analysis.htm" target="">Accord.Statistics.Analysis</a><br /><b>Assembly:</b> <span sdata="assembly">Accord.Statistics</span> (in Accord.Statistics.dll) Version: 2.10.0.0 (2.10.0.0)<div class="OH_CollapsibleAreaRegion"><div class="OH_regiontitle">Syntax</div><div class="OH_CollapsibleArea_HrDiv"><hr class="OH_CollapsibleArea_Hr" /></div></div><div class="OH_clear"></div><div id="snippetGroup_Syntax" class="code"><div id="ID0EAAEAAAAA" class="OH_CodeSnippetContainer"><div class="OH_CodeSnippetContainerTabs" id="ID0EAAEAAAAA_tabs"><div class="OH_CodeSnippetContainerTabLeftActive" id="ID0EAAEAAAAA_tabimgleft"></div><div id="ID0EAAEAAAAA_tab1" class="OH_CodeSnippetContainerTabActive" EnableCopyCode="true"><a href="#" onclick="javascript:ChangeTab('ID0EAAEAAAAA','C#','1','4');return false;">C#</a></div><div id="ID0EAAEAAAAA_tab2" class="OH_CodeSnippetContainerTabDisabledNotFirst" EnableCopyCode="true" disabled="true"><a>VB</a></div><div id="ID0EAAEAAAAA_tab3" class="OH_CodeSnippetContainerTabDisabledNotFirst" EnableCopyCode="true" disabled="true"><a>C++</a></div><div id="ID0EAAEAAAAA_tab4" class="OH_CodeSnippetContainerTabDisabledNotFirst" EnableCopyCode="true" disabled="true"><a>F#</a></div><div class="OH_CodeSnippetContainerTabRight" id="ID0EAAEAAAAA_tabimgright"></div></div><div id="ID0EAAEAAAAA_codecollection" class="OH_CodeSnippetContainerCodeCollection"><div class="OH_CodeSnippetToolBar"><div class="OH_CodeSnippetToolBarText"><a id="ID0EAAEAAAAA_ViewColorized" href="#" onclick="javascript:ExchangeTitleContent('ID0EAAEAAAAA','4')" title="View Colorized" style="display: none">View Colorized</a><a id="ID0EAAEAAAAA_copycode" href="#" onclick="javascript:CopyToClipboard('ID0EAAEAAAAA','4')" title="Copy to Clipboard">Copy to Clipboard</a><a id="ID0EAAEAAAAA_PrintText" class="OH_PrintText" href="#" onclick="javascript:Print('ID0EAAEAAAAA','4')" title="Print">Print</a></div></div><div id="ID0EAAEAAAAA_code_Div1" class="OH_CodeSnippetContainerCode" style="display: block"><pre>[<span class="identifier">SerializableAttribute</span>]
<span class="keyword">public</span> <span class="keyword">class</span> <span class="identifier">PrincipalComponentAnalysis</span> : <span class="identifier">IProjectionAnalysis</span>, 
	<span class="identifier">IMultivariateAnalysis</span>, <span class="identifier">IAnalysis</span></pre></div><div id="ID0EAAEAAAAA_code_Plain_Div1" class="OH_CodeSnippetContainerCode" style="display: none"><pre>[SerializableAttribute]
public class PrincipalComponentAnalysis : IProjectionAnalysis, 
	IMultivariateAnalysis, IAnalysis</pre></div><div id="ID0EAAEAAAAA_code_Div2" class="OH_CodeSnippetContainerCode" style="display: none"><pre /></div><div id="ID0EAAEAAAAA_code_Plain_Div2" class="OH_CodeSnippetContainerCode" style="display: none"><pre /></div><div id="ID0EAAEAAAAA_code_Div3" class="OH_CodeSnippetContainerCode" style="display: none"><pre /></div><div id="ID0EAAEAAAAA_code_Plain_Div3" class="OH_CodeSnippetContainerCode" style="display: none"><pre /></div><div id="ID0EAAEAAAAA_code_Div4" class="OH_CodeSnippetContainerCode" style="display: none"><pre /></div><div id="ID0EAAEAAAAA_code_Plain_Div4" class="OH_CodeSnippetContainerCode" style="display: none"><pre /></div></div></div><script>addSpecificTextLanguageTagSet('ID0EAAEAAAAA');</script></div><div class="OH_CollapsibleAreaRegion"><div class="OH_regiontitle">Remarks</div><div class="OH_CollapsibleArea_HrDiv"><hr class="OH_CollapsibleArea_Hr" /></div></div><div class="OH_clear"></div><p>
               Principal Components Analysis or the Karhunen-Loeve expansion is a
               classical method for dimensionality reduction or exploratory data
               analysis.</p><p>
               Mathematically, PCA is a process that decomposes the covariance matrix of a matrix
               into two parts: eigenvalues and column eigenvectors, whereas Singular Value Decomposition
               (SVD) decomposes a matrix per se into three parts: singular values, column eigenvectors,
               and row eigenvectors. The relationships between PCA and SVD lie in that the eigenvalues 
               are the square of the singular values and the column vectors are the same for both.</p><p>
               This class uses SVD on the data set which generally gives better numerical accuracy.</p><p>
               This class can also be bound to standard controls such as the 
               <img src="./../icons/online_icon.gif" class="OH_offlineIcon" alt="Online" title="Online" /><a href="http://msdn.microsoft.com/en-us/library/system.windows.forms.datagridview.aspx" target="_blank">DataGridView</a>
               by setting their DataSource property to the analysis' <a href="P_Accord_Statistics_Analysis_PrincipalComponentAnalysis_Components.htm" target="">Components</a> property.</p><div class="OH_CollapsibleAreaRegion"><div class="OH_regiontitle">Examples</div><div class="OH_CollapsibleArea_HrDiv"><hr class="OH_CollapsibleArea_Hr" /></div></div><div class="OH_clear"></div><p>
                The example below shows a typical usage of the analysis. However, users
                often ask why the framework produces different values than other packages
                such as STATA or MATLAB. After the simple introductory example below, we
                will be exploring why those results are often different.</p><div id="ID0EGCAAAAA" class="OH_CodeSnippetContainer"><div class="OH_CodeSnippetContainerTabs" id="ID0EGCAAAAA_tabs"></div><div id="ID0EGCAAAAA_codecollection" class="OH_CodeSnippetContainerCodeCollection"><div class="OH_CodeSnippetToolBar"><div class="OH_CodeSnippetToolBarText"><a id="ID0EGCAAAAA_ViewColorized" href="#" onclick="javascript:ExchangeTitleContent('ID0EGCAAAAA','4')" title="View Colorized" style="display: none">View Colorized</a><a id="ID0EGCAAAAA_copycode" href="#" onclick="javascript:CopyToClipboard('ID0EGCAAAAA','4')" title="Copy to Clipboard">Copy to Clipboard</a><a id="ID0EGCAAAAA_PrintText" class="OH_PrintText" href="#" onclick="javascript:Print('ID0EGCAAAAA','4')" title="Print">Print</a></div></div><div id="ID0EGCAAAAA_code_Div1" class="OH_CodeSnippetContainerCode" style="display: block"><pre><span class="highlight-comment">// Below is the same data used on the excellent paper "Tutorial</span> 
<span class="highlight-comment">//   On Principal Component Analysis", by Lindsay Smith (2002).</span> 

<span class="highlight-keyword">double</span>[,] sourceMatrix = 
{
    { <span class="highlight-number">2.5</span>,  <span class="highlight-number">2.4</span> },
    { <span class="highlight-number">0.5</span>,  <span class="highlight-number">0.7</span> },
    { <span class="highlight-number">2.2</span>,  <span class="highlight-number">2.9</span> },
    { <span class="highlight-number">1.9</span>,  <span class="highlight-number">2.2</span> },
    { <span class="highlight-number">3.1</span>,  <span class="highlight-number">3.0</span> },
    { <span class="highlight-number">2.3</span>,  <span class="highlight-number">2.7</span> },
    { <span class="highlight-number">2.0</span>,  <span class="highlight-number">1.6</span> },
    { <span class="highlight-number">1.0</span>,  <span class="highlight-number">1.1</span> },
    { <span class="highlight-number">1.5</span>,  <span class="highlight-number">1.6</span> },
    { <span class="highlight-number">1.1</span>,  <span class="highlight-number">0.9</span> }
}; 

<span class="highlight-comment">// Creates the Principal Component Analysis of the given source</span> 
<span class="highlight-keyword">var</span> pca = <span class="highlight-keyword">new</span> PrincipalComponentAnalysis(sourceMatrix, AnalysisMethod.Center);

<span class="highlight-comment">// Compute the Principal Component Analysis</span>
pca.Compute();

<span class="highlight-comment">// Creates a projection considering 80% of the information</span> 
<span class="highlight-keyword">double</span>[,] components = pca.Transform(sourceMatrix, <span class="highlight-number">0.8</span>f, <span class="highlight-keyword">true</span>);</pre></div><div id="ID0EGCAAAAA_code_Plain_Div1" class="OH_CodeSnippetContainerCode" style="display: none"><pre>// Below is the same data used on the excellent paper "Tutorial 
//   On Principal Component Analysis", by Lindsay Smith (2002). 

double[,] sourceMatrix = 
{
    { 2.5,  2.4 },
    { 0.5,  0.7 },
    { 2.2,  2.9 },
    { 1.9,  2.2 },
    { 3.1,  3.0 },
    { 2.3,  2.7 },
    { 2.0,  1.6 },
    { 1.0,  1.1 },
    { 1.5,  1.6 },
    { 1.1,  0.9 }
}; 

// Creates the Principal Component Analysis of the given source 
var pca = new PrincipalComponentAnalysis(sourceMatrix, AnalysisMethod.Center);

// Compute the Principal Component Analysis
pca.Compute();

// Creates a projection considering 80% of the information 
double[,] components = pca.Transform(sourceMatrix, 0.8f, true);</pre></div></div></div><script>addSpecificTextLanguageTagSet('ID0EGCAAAAA');</script><p>
                A question often asked by users is "why my matrices have inverted
                signs" or "why my results differ from [another software]". In short,
                despite any differences, the results are most likely correct (unless
                you firmly believes you have found a bug; in this case, please fill 
                in a bug report). </p><p>
                The example below explores, in the same steps given in Lindsay's
                tutorial, anything that would cause any discrepancies between the
                results given by Accord.NET and results given by other softwares.</p><div id="ID0EDCAAAAA" class="OH_CodeSnippetContainer"><div class="OH_CodeSnippetContainerTabs" id="ID0EDCAAAAA_tabs"></div><div id="ID0EDCAAAAA_codecollection" class="OH_CodeSnippetContainerCodeCollection"><div class="OH_CodeSnippetToolBar"><div class="OH_CodeSnippetToolBarText"><a id="ID0EDCAAAAA_ViewColorized" href="#" onclick="javascript:ExchangeTitleContent('ID0EDCAAAAA','4')" title="View Colorized" style="display: none">View Colorized</a><a id="ID0EDCAAAAA_copycode" href="#" onclick="javascript:CopyToClipboard('ID0EDCAAAAA','4')" title="Copy to Clipboard">Copy to Clipboard</a><a id="ID0EDCAAAAA_PrintText" class="OH_PrintText" href="#" onclick="javascript:Print('ID0EDCAAAAA','4')" title="Print">Print</a></div></div><div id="ID0EDCAAAAA_code_Div1" class="OH_CodeSnippetContainerCode" style="display: block"><pre><span class="highlight-comment">// Reproducing Lindsay Smith's "Tutorial on Principal Component Analysis"</span> 
<span class="highlight-comment">// using the framework's default method. The tutorial can be found online</span> 
<span class="highlight-comment">// at http://www.sccg.sk/~haladova/principal_components.pdf</span> 

<span class="highlight-comment">// Step 1. Get some data</span> 
<span class="highlight-comment">// ---------------------</span> 

<span class="highlight-keyword">double</span>[,] data = 
{
    { <span class="highlight-number">2.5</span>,  <span class="highlight-number">2.4</span> },
    { <span class="highlight-number">0.5</span>,  <span class="highlight-number">0.7</span> },
    { <span class="highlight-number">2.2</span>,  <span class="highlight-number">2.9</span> },
    { <span class="highlight-number">1.9</span>,  <span class="highlight-number">2.2</span> },
    { <span class="highlight-number">3.1</span>,  <span class="highlight-number">3.0</span> },
    { <span class="highlight-number">2.3</span>,  <span class="highlight-number">2.7</span> },
    { <span class="highlight-number">2.0</span>,  <span class="highlight-number">1.6</span> },
    { <span class="highlight-number">1.0</span>,  <span class="highlight-number">1.1</span> },
    { <span class="highlight-number">1.5</span>,  <span class="highlight-number">1.6</span> },
    { <span class="highlight-number">1.1</span>,  <span class="highlight-number">0.9</span> }
};


<span class="highlight-comment">// Step 2. Subtract the mean</span> 
<span class="highlight-comment">// -------------------------</span> 
<span class="highlight-comment">//   Note: The framework does this automatically. By default, the framework</span> 
<span class="highlight-comment">//   uses the "Center" method, which only subtracts the mean. However, it is</span> 
<span class="highlight-comment">//   also possible to remove the mean *and* divide by the standard deviation</span> 
<span class="highlight-comment">//   (thus performing the correlation method) by specifying "Standardize"</span> 
<span class="highlight-comment">//   instead of "Center" as the AnalysisMethod.</span>

AnalysisMethod method = AnalysisMethod.Center; <span class="highlight-comment">// AnalysisMethod.Standardize</span> 


<span class="highlight-comment">// Step 3. Compute the covariance matrix</span> 
<span class="highlight-comment">// -------------------------------------</span> 
<span class="highlight-comment">//   Note: Accord.NET does not need to compute the covariance</span> 
<span class="highlight-comment">//   matrix in order to compute PCA. The framework uses the SVD</span> 
<span class="highlight-comment">//   method which is more numerically stable, but may require</span> 
<span class="highlight-comment">//   more processing or memory. In order to replicate the tutorial</span> 
<span class="highlight-comment">//   using covariance matrices, please see the next example below.</span> 

<span class="highlight-comment">// Create the analysis using the selected method</span> 
<span class="highlight-keyword">var</span> pca = <span class="highlight-keyword">new</span> PrincipalComponentAnalysis(data, method);

<span class="highlight-comment">// Compute it</span>
pca.Compute();


<span class="highlight-comment">// Step 4. Compute the eigenvectors and eigenvalues of the covariance matrix</span> 
<span class="highlight-comment">// -------------------------------------------------------------------------</span> 
<span class="highlight-comment">//   Note: Since Accord.NET uses the SVD method rather than the Eigendecomposition</span> 
<span class="highlight-comment">//   method, the Eigenvalues are not directly available. However, it is not the</span> 
<span class="highlight-comment">//   Eigenvalues themselves which are important, but rather their proportion:</span> 

<span class="highlight-comment">// Those are the expected eigenvalues, in descending order:</span> 
<span class="highlight-keyword">double</span>[] eigenvalues = { <span class="highlight-number">1.28402771</span>, <span class="highlight-number">0.0490833989</span> };

<span class="highlight-comment">// And this will be their proportion:</span> 
<span class="highlight-keyword">double</span>[] proportion = eigenvalues.Divide(eigenvalues.Sum());

<span class="highlight-comment">// Those are the expected eigenvectors,</span> 
<span class="highlight-comment">// in descending order of eigenvalues:</span> 
<span class="highlight-keyword">double</span>[,] eigenvectors =
{
    { <span class="highlight-number">-0.677873399</span>, <span class="highlight-number">-0.735178656</span> },
    { <span class="highlight-number">-0.735178656</span>,  <span class="highlight-number">0.677873399</span> }
};

<span class="highlight-comment">// Now, here is the place most users get confused. The fact is that</span> 
<span class="highlight-comment">// the Eigenvalue decomposition (EVD) is not unique, and both the SVD</span> 
<span class="highlight-comment">// and EVD routines used by the framework produces results which are</span> 
<span class="highlight-comment">// numerically different from packages such as STATA or MATLAB, but</span> 
<span class="highlight-comment">// those are correct.</span> 

<span class="highlight-comment">// If v is an eigenvector, a multiple of this eigenvector (such as a*v, with</span> 
<span class="highlight-comment">// a being a scalar) will also be an eigenvector. In the Lindsay case, the</span> 
<span class="highlight-comment">// framework produces a first eigenvector with inverted signs. This is the same</span> 
<span class="highlight-comment">// as considering a=-1 and taking a*v. The result is still correct.</span> 

<span class="highlight-comment">// Retrieve the first expected eigenvector</span> 
<span class="highlight-keyword">double</span>[] v = eigenvectors.GetColumn(<span class="highlight-number">0</span>);

<span class="highlight-comment">// Multiply by a scalar and store it back</span>
eigenvectors.SetColumn(<span class="highlight-number">0</span>, v.Multiply(<span class="highlight-number">-1</span>));

<span class="highlight-comment">// At this point, the eigenvectors should equal the pca.ComponentMatrix,</span> 
<span class="highlight-comment">// and the proportion vector should equal the pca.ComponentProportions up</span> 
<span class="highlight-comment">// to the 9 decimal places shown in the tutorial.</span> 


<span class="highlight-comment">// Step 5. Deriving the new data set</span> 
<span class="highlight-comment">// ---------------------------------</span> 

<span class="highlight-keyword">double</span>[,] actual = pca.Transform(data);

<span class="highlight-comment">// transformedData shown in pg. 18</span> 
<span class="highlight-keyword">double</span>[,] expected = <span class="highlight-keyword">new</span> <span class="highlight-keyword">double</span>[,]
{
    {  <span class="highlight-number">0.827970186</span>, <span class="highlight-number">-0.175115307</span> },
    { <span class="highlight-number">-1.77758033</span>,   <span class="highlight-number">0.142857227</span> },
    {  <span class="highlight-number">0.992197494</span>,  <span class="highlight-number">0.384374989</span> },
    {  <span class="highlight-number">0.274210416</span>,  <span class="highlight-number">0.130417207</span> },
    {  <span class="highlight-number">1.67580142</span>,  <span class="highlight-number">-0.209498461</span> },
    {  <span class="highlight-number">0.912949103</span>,  <span class="highlight-number">0.175282444</span> },
    { <span class="highlight-number">-0.099109437</span>, <span class="highlight-number">-0.349824698</span> },
    { <span class="highlight-number">-1.14457216</span>,   <span class="highlight-number">0.046417258</span> },
    { <span class="highlight-number">-0.438046137</span>,  <span class="highlight-number">0.017764629</span> },
    { <span class="highlight-number">-1.22382056</span>,  <span class="highlight-number">-0.162675287</span> },
};

<span class="highlight-comment">// At this point, the actual and expected matrices</span> 
<span class="highlight-comment">// should be equal up to 8 decimal places.</span></pre></div><div id="ID0EDCAAAAA_code_Plain_Div1" class="OH_CodeSnippetContainerCode" style="display: none"><pre>// Reproducing Lindsay Smith's "Tutorial on Principal Component Analysis" 
// using the framework's default method. The tutorial can be found online 
// at http://www.sccg.sk/~haladova/principal_components.pdf 

// Step 1. Get some data 
// --------------------- 

double[,] data = 
{
    { 2.5,  2.4 },
    { 0.5,  0.7 },
    { 2.2,  2.9 },
    { 1.9,  2.2 },
    { 3.1,  3.0 },
    { 2.3,  2.7 },
    { 2.0,  1.6 },
    { 1.0,  1.1 },
    { 1.5,  1.6 },
    { 1.1,  0.9 }
};


// Step 2. Subtract the mean 
// ------------------------- 
//   Note: The framework does this automatically. By default, the framework 
//   uses the "Center" method, which only subtracts the mean. However, it is 
//   also possible to remove the mean *and* divide by the standard deviation 
//   (thus performing the correlation method) by specifying "Standardize" 
//   instead of "Center" as the AnalysisMethod.

AnalysisMethod method = AnalysisMethod.Center; // AnalysisMethod.Standardize 


// Step 3. Compute the covariance matrix 
// ------------------------------------- 
//   Note: Accord.NET does not need to compute the covariance 
//   matrix in order to compute PCA. The framework uses the SVD 
//   method which is more numerically stable, but may require 
//   more processing or memory. In order to replicate the tutorial 
//   using covariance matrices, please see the next example below. 

// Create the analysis using the selected method 
var pca = new PrincipalComponentAnalysis(data, method);

// Compute it
pca.Compute();


// Step 4. Compute the eigenvectors and eigenvalues of the covariance matrix 
// ------------------------------------------------------------------------- 
//   Note: Since Accord.NET uses the SVD method rather than the Eigendecomposition 
//   method, the Eigenvalues are not directly available. However, it is not the 
//   Eigenvalues themselves which are important, but rather their proportion: 

// Those are the expected eigenvalues, in descending order: 
double[] eigenvalues = { 1.28402771, 0.0490833989 };

// And this will be their proportion: 
double[] proportion = eigenvalues.Divide(eigenvalues.Sum());

// Those are the expected eigenvectors, 
// in descending order of eigenvalues: 
double[,] eigenvectors =
{
    { -0.677873399, -0.735178656 },
    { -0.735178656,  0.677873399 }
};

// Now, here is the place most users get confused. The fact is that 
// the Eigenvalue decomposition (EVD) is not unique, and both the SVD 
// and EVD routines used by the framework produces results which are 
// numerically different from packages such as STATA or MATLAB, but 
// those are correct. 

// If v is an eigenvector, a multiple of this eigenvector (such as a*v, with 
// a being a scalar) will also be an eigenvector. In the Lindsay case, the 
// framework produces a first eigenvector with inverted signs. This is the same 
// as considering a=-1 and taking a*v. The result is still correct. 

// Retrieve the first expected eigenvector 
double[] v = eigenvectors.GetColumn(0);

// Multiply by a scalar and store it back
eigenvectors.SetColumn(0, v.Multiply(-1));

// At this point, the eigenvectors should equal the pca.ComponentMatrix, 
// and the proportion vector should equal the pca.ComponentProportions up 
// to the 9 decimal places shown in the tutorial. 


// Step 5. Deriving the new data set 
// --------------------------------- 

double[,] actual = pca.Transform(data);

// transformedData shown in pg. 18 
double[,] expected = new double[,]
{
    {  0.827970186, -0.175115307 },
    { -1.77758033,   0.142857227 },
    {  0.992197494,  0.384374989 },
    {  0.274210416,  0.130417207 },
    {  1.67580142,  -0.209498461 },
    {  0.912949103,  0.175282444 },
    { -0.099109437, -0.349824698 },
    { -1.14457216,   0.046417258 },
    { -0.438046137,  0.017764629 },
    { -1.22382056,  -0.162675287 },
};

// At this point, the actual and expected matrices 
// should be equal up to 8 decimal places.</pre></div></div></div><script>addSpecificTextLanguageTagSet('ID0EDCAAAAA');</script><p>
                Some users would like to analyze huge amounts of data. In this case,
                computing the SVD directly on the data could result in memory exceptions
                or excessive computing times. If your data's number of dimensions is much
                less than the number of observations (i.e. your matrix have less columns
                than rows) then it would be a better idea to summarize your data in the
                form of a covariance or correlation matrix and compute PCA using the EVD.</p><p>
                The example below shows how to compute the analysis with covariance
                matrices only.</p><div id="ID0EACAAAAA" class="OH_CodeSnippetContainer"><div class="OH_CodeSnippetContainerTabs" id="ID0EACAAAAA_tabs"></div><div id="ID0EACAAAAA_codecollection" class="OH_CodeSnippetContainerCodeCollection"><div class="OH_CodeSnippetToolBar"><div class="OH_CodeSnippetToolBarText"><a id="ID0EACAAAAA_ViewColorized" href="#" onclick="javascript:ExchangeTitleContent('ID0EACAAAAA','4')" title="View Colorized" style="display: none">View Colorized</a><a id="ID0EACAAAAA_copycode" href="#" onclick="javascript:CopyToClipboard('ID0EACAAAAA','4')" title="Copy to Clipboard">Copy to Clipboard</a><a id="ID0EACAAAAA_PrintText" class="OH_PrintText" href="#" onclick="javascript:Print('ID0EACAAAAA','4')" title="Print">Print</a></div></div><div id="ID0EACAAAAA_code_Div1" class="OH_CodeSnippetContainerCode" style="display: block"><pre><span class="highlight-comment">// Reproducing Lindsay Smith's "Tutorial on Principal Component Analysis"</span> 
<span class="highlight-comment">// using the paper's original method. The tutorial can be found online</span> 
<span class="highlight-comment">// at http://www.sccg.sk/~haladova/principal_components.pdf</span> 

<span class="highlight-comment">// Step 1. Get some data</span> 
<span class="highlight-comment">// ---------------------</span> 

<span class="highlight-keyword">double</span>[,] data = 
{
    { <span class="highlight-number">2.5</span>,  <span class="highlight-number">2.4</span> },
    { <span class="highlight-number">0.5</span>,  <span class="highlight-number">0.7</span> },
    { <span class="highlight-number">2.2</span>,  <span class="highlight-number">2.9</span> },
    { <span class="highlight-number">1.9</span>,  <span class="highlight-number">2.2</span> },
    { <span class="highlight-number">3.1</span>,  <span class="highlight-number">3.0</span> },
    { <span class="highlight-number">2.3</span>,  <span class="highlight-number">2.7</span> },
    { <span class="highlight-number">2.0</span>,  <span class="highlight-number">1.6</span> },
    { <span class="highlight-number">1.0</span>,  <span class="highlight-number">1.1</span> },
    { <span class="highlight-number">1.5</span>,  <span class="highlight-number">1.6</span> },
    { <span class="highlight-number">1.1</span>,  <span class="highlight-number">0.9</span> }
};


<span class="highlight-comment">// Step 2. Subtract the mean</span> 
<span class="highlight-comment">// -------------------------</span> 
<span class="highlight-comment">//   Note: The framework does this automatically </span> 
<span class="highlight-comment">//   when computing the covariance matrix. In this</span> 
<span class="highlight-comment">//   step we will only compute the mean vector.</span> 

<span class="highlight-keyword">double</span>[] mean = Accord.Statistics.Tools.Mean(data);


<span class="highlight-comment">// Step 3. Compute the covariance matrix</span> 
<span class="highlight-comment">// -------------------------------------</span> 

<span class="highlight-keyword">double</span>[,] covariance = Accord.Statistics.Tools.Covariance(data, mean);

<span class="highlight-comment">// Create the analysis using the covariance matrix</span> 
<span class="highlight-keyword">var</span> pca = PrincipalComponentAnalysis.FromCovarianceMatrix(mean, covariance);

<span class="highlight-comment">// Compute it</span>
pca.Compute();


<span class="highlight-comment">// Step 4. Compute the eigenvectors and eigenvalues of the covariance matrix</span> 
<span class="highlight-comment">//--------------------------------------------------------------------------</span> 

<span class="highlight-comment">// Those are the expected eigenvalues, in descending order:</span> 
<span class="highlight-keyword">double</span>[] eigenvalues = { <span class="highlight-number">1.28402771</span>, <span class="highlight-number">0.0490833989</span> };

<span class="highlight-comment">// And this will be their proportion:</span> 
<span class="highlight-keyword">double</span>[] proportion = eigenvalues.Divide(eigenvalues.Sum());

<span class="highlight-comment">// Those are the expected eigenvectors,</span> 
<span class="highlight-comment">// in descending order of eigenvalues:</span> 
<span class="highlight-keyword">double</span>[,] eigenvectors =
{
    { <span class="highlight-number">-0.677873399</span>, <span class="highlight-number">-0.735178656</span> },
    { <span class="highlight-number">-0.735178656</span>,  <span class="highlight-number">0.677873399</span> }
};

<span class="highlight-comment">// Now, here is the place most users get confused. The fact is that</span> 
<span class="highlight-comment">// the Eigenvalue decomposition (EVD) is not unique, and both the SVD</span> 
<span class="highlight-comment">// and EVD routines used by the framework produces results which are</span> 
<span class="highlight-comment">// numerically different from packages such as STATA or MATLAB, but</span> 
<span class="highlight-comment">// those are correct.</span> 

<span class="highlight-comment">// If v is an eigenvector, a multiple of this eigenvector (such as a*v, with</span> 
<span class="highlight-comment">// a being a scalar) will also be an eigenvector. In the Lindsay case, the</span> 
<span class="highlight-comment">// framework produces a first eigenvector with inverted signs. This is the same</span> 
<span class="highlight-comment">// as considering a=-1 and taking a*v. The result is still correct.</span> 

<span class="highlight-comment">// Retrieve the first expected eigenvector</span> 
<span class="highlight-keyword">double</span>[] v = eigenvectors.GetColumn(<span class="highlight-number">0</span>);

<span class="highlight-comment">// Multiply by a scalar and store it back</span>
eigenvectors.SetColumn(<span class="highlight-number">0</span>, v.Multiply(<span class="highlight-number">-1</span>));

<span class="highlight-comment">// At this point, the eigenvectors should equal the pca.ComponentMatrix,</span> 
<span class="highlight-comment">// and the proportion vector should equal the pca.ComponentProportions up</span> 
<span class="highlight-comment">// to the 9 decimal places shown in the tutorial. Moreover, unlike the</span> 
<span class="highlight-comment">// previous example, the eigenvalues vector should also be equal to the</span> 
<span class="highlight-comment">// property pca.Eigenvalues.</span> 


<span class="highlight-comment">// Step 5. Deriving the new data set</span> 
<span class="highlight-comment">// ---------------------------------</span> 

<span class="highlight-keyword">double</span>[,] actual = pca.Transform(data);

<span class="highlight-comment">// transformedData shown in pg. 18</span> 
<span class="highlight-keyword">double</span>[,] expected = <span class="highlight-keyword">new</span> <span class="highlight-keyword">double</span>[,]
{
    {  <span class="highlight-number">0.827970186</span>, <span class="highlight-number">-0.175115307</span> },
    { <span class="highlight-number">-1.77758033</span>,   <span class="highlight-number">0.142857227</span> },
    {  <span class="highlight-number">0.992197494</span>,  <span class="highlight-number">0.384374989</span> },
    {  <span class="highlight-number">0.274210416</span>,  <span class="highlight-number">0.130417207</span> },
    {  <span class="highlight-number">1.67580142</span>,  <span class="highlight-number">-0.209498461</span> },
    {  <span class="highlight-number">0.912949103</span>,  <span class="highlight-number">0.175282444</span> },
    { <span class="highlight-number">-0.099109437</span>, <span class="highlight-number">-0.349824698</span> },
    { <span class="highlight-number">-1.14457216</span>,   <span class="highlight-number">0.046417258</span> },
    { <span class="highlight-number">-0.438046137</span>,  <span class="highlight-number">0.017764629</span> },
    { <span class="highlight-number">-1.22382056</span>,  <span class="highlight-number">-0.162675287</span> },
};

<span class="highlight-comment">// At this point, the actual and expected matrices</span> 
<span class="highlight-comment">// should be equal up to 8 decimal places.</span></pre></div><div id="ID0EACAAAAA_code_Plain_Div1" class="OH_CodeSnippetContainerCode" style="display: none"><pre>// Reproducing Lindsay Smith's "Tutorial on Principal Component Analysis" 
// using the paper's original method. The tutorial can be found online 
// at http://www.sccg.sk/~haladova/principal_components.pdf 

// Step 1. Get some data 
// --------------------- 

double[,] data = 
{
    { 2.5,  2.4 },
    { 0.5,  0.7 },
    { 2.2,  2.9 },
    { 1.9,  2.2 },
    { 3.1,  3.0 },
    { 2.3,  2.7 },
    { 2.0,  1.6 },
    { 1.0,  1.1 },
    { 1.5,  1.6 },
    { 1.1,  0.9 }
};


// Step 2. Subtract the mean 
// ------------------------- 
//   Note: The framework does this automatically  
//   when computing the covariance matrix. In this 
//   step we will only compute the mean vector. 

double[] mean = Accord.Statistics.Tools.Mean(data);


// Step 3. Compute the covariance matrix 
// ------------------------------------- 

double[,] covariance = Accord.Statistics.Tools.Covariance(data, mean);

// Create the analysis using the covariance matrix 
var pca = PrincipalComponentAnalysis.FromCovarianceMatrix(mean, covariance);

// Compute it
pca.Compute();


// Step 4. Compute the eigenvectors and eigenvalues of the covariance matrix 
//-------------------------------------------------------------------------- 

// Those are the expected eigenvalues, in descending order: 
double[] eigenvalues = { 1.28402771, 0.0490833989 };

// And this will be their proportion: 
double[] proportion = eigenvalues.Divide(eigenvalues.Sum());

// Those are the expected eigenvectors, 
// in descending order of eigenvalues: 
double[,] eigenvectors =
{
    { -0.677873399, -0.735178656 },
    { -0.735178656,  0.677873399 }
};

// Now, here is the place most users get confused. The fact is that 
// the Eigenvalue decomposition (EVD) is not unique, and both the SVD 
// and EVD routines used by the framework produces results which are 
// numerically different from packages such as STATA or MATLAB, but 
// those are correct. 

// If v is an eigenvector, a multiple of this eigenvector (such as a*v, with 
// a being a scalar) will also be an eigenvector. In the Lindsay case, the 
// framework produces a first eigenvector with inverted signs. This is the same 
// as considering a=-1 and taking a*v. The result is still correct. 

// Retrieve the first expected eigenvector 
double[] v = eigenvectors.GetColumn(0);

// Multiply by a scalar and store it back
eigenvectors.SetColumn(0, v.Multiply(-1));

// At this point, the eigenvectors should equal the pca.ComponentMatrix, 
// and the proportion vector should equal the pca.ComponentProportions up 
// to the 9 decimal places shown in the tutorial. Moreover, unlike the 
// previous example, the eigenvalues vector should also be equal to the 
// property pca.Eigenvalues. 


// Step 5. Deriving the new data set 
// --------------------------------- 

double[,] actual = pca.Transform(data);

// transformedData shown in pg. 18 
double[,] expected = new double[,]
{
    {  0.827970186, -0.175115307 },
    { -1.77758033,   0.142857227 },
    {  0.992197494,  0.384374989 },
    {  0.274210416,  0.130417207 },
    {  1.67580142,  -0.209498461 },
    {  0.912949103,  0.175282444 },
    { -0.099109437, -0.349824698 },
    { -1.14457216,   0.046417258 },
    { -0.438046137,  0.017764629 },
    { -1.22382056,  -0.162675287 },
};

// At this point, the actual and expected matrices 
// should be equal up to 8 decimal places.</pre></div></div></div><script>addSpecificTextLanguageTagSet('ID0EACAAAAA');</script><a name="seeAlsoSection"><!----></a><div class="OH_CollapsibleAreaRegion"><div class="OH_regiontitle">See Also</div><div class="OH_CollapsibleArea_HrDiv"><hr class="OH_CollapsibleArea_Hr" /></div></div><div class="OH_clear"></div><div class="seeAlsoStyle"><a href="AllMembers_T_Accord_Statistics_Analysis_PrincipalComponentAnalysis.htm" target="">PrincipalComponentAnalysis Members</a></div><div class="seeAlsoStyle"><a href="N_Accord_Statistics_Analysis.htm" target="">Accord.Statistics.Analysis Namespace</a></div></div>
        </div>
      </div>
    </div>
    <div id="OH_footer" class="OH_footer">
      <p>
        <a href="http://accord-net.github.io/" target="_blank">Accord.NET Framework</a> © 2009-2013. All documentation is licensed under the Creative Commons Attribution/Share-Alike License.</p>
      <div class="OH_feedbacklink">
        <a href="mailto:?subject=Accord.NET+Framework+PrincipalComponentAnalysis+Class+100+EN-US&amp;body=Your%20feedback%20is%20used%20to%20improve%20the%20documentation%20and%20the%20product.%20Your%20e-mail%20address%20will%20not%20be%20used%20for%20any%20other%20purpose%20and%20is%20disposed%20of%20after%20the%20issue%20you%20report%20is%20resolved.%20While%20working%20to%20resolve%20the%20issue%20that%20you%20report%2c%20you%20may%20be%20contacted%20via%20e-mail%20to%20get%20further%20details%20or%20clarification%20on%20the%20feedback%20you%20sent.%20After%20the%20issue%20you%20report%20has%20been%20addressed%2c%20you%20may%20receive%20an%20e-mail%20to%20let%20you%20know%20that%20your%20feedback%20has%20been%20addressed.">Send Feedback</a> on this topic.</div>
    </div>
  </body>
</html>